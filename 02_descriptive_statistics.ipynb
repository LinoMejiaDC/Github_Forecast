{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "#from pandas.tools.plotting import autocorrelation_plot\n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH WHERE THE FILES ARE SAVED\n",
    "# path = r'/dbfs/FileStore/tables/'\n",
    "path = './'\n",
    "\n",
    "# IMPORT OF DATABASE\n",
    "ddf = pd.read_excel(path + r'/2_cleaned_data/clean_ddf.xlsx')\n",
    "\n",
    "# IMPORT OF VARIABLES FROM PRE-PROCESSING NOTEBOOK\n",
    "preprocess1 = (path + r'/3_variables/var1_pre_processing.sav')\n",
    "num_nan, inv_values = pickle.load(open(preprocess1, 'rb'))\n",
    "\n",
    "preprocess2 = (path + r'/3_variables/var2_pre_processing.sav')\n",
    "outlier_df = pickle.load(open(preprocess2, 'rb'))\n",
    "\n",
    "# IMPORT OF DATA FROM FRAMEWORK CONFIGURATION\n",
    "frameworkconfig1 = (path + r'/3_variables/var1_framework_config.sav')\n",
    "ddf_config_var = pickle.load(open(frameworkconfig1, 'rb'))\n",
    "\n",
    "# frameworkconfig2 = (path + r'/3_variables/var2_framework_config.sav')\n",
    "# ddf_config_kpi = pickle.load(open(frameworkconfig2, 'rb'))\n",
    "\n",
    "frameworkconfig3 = (path + r'/3_variables/var3_framework_config.sav')\n",
    "ddf_config_par = pickle.load(open(frameworkconfig3, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY KEY\n",
    "primary_key = ddf_config_var.loc[np.where(ddf_config_var[\"VariableUsage\"]=='PRIMARY')[0][0],'VariableName']\n",
    "\n",
    "# FILTER BY COLUMN\n",
    "filter_by = ddf_config_par.loc[0,'Value']\n",
    "\n",
    "# FILTER BY VALUE\n",
    "filter_value = ddf_config_par.loc[1,'Value']\n",
    "\n",
    "if str(filter_by)!='nan':\n",
    "    # PRIMARY KEY LIST WITH FILTER \n",
    "    pk_list = ddf[primary_key][ddf[filter_by]==filter_value].unique()\n",
    "else:\n",
    "    # PRIMARY KEY LIST \n",
    "    pk_list = ddf[primary_key].unique()\n",
    "    \n",
    "# DATETIME VARIABLE\n",
    "date_column = ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='DATETIME')[0][0],'VariableName']\n",
    "\n",
    "# TARGET VARIABLE\n",
    "target = ddf_config_var.loc[np.where(ddf_config_var[\"VariableUsage\"]=='TARGET')[0][0],'VariableName']\n",
    "\n",
    "# EXOGENOUS VARIABLE\n",
    "exogenous = []\n",
    "for i in ddf_config_var.loc[np.where(ddf_config_var[\"VariableUsage\"]=='EXOGENOUS')[0],'VariableName']:\n",
    "    exogenous.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='DATETIME')[0],'VariableName'])\n",
    "numeric_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='NUMERIC')[0],'VariableName']) \n",
    "categorical_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='CATEGORICAL')[0],'VariableName'])\n",
    "\n",
    "# VARIABLES FORMAT\n",
    "ddf[time_variables] = ddf[time_variables].astype('object')\n",
    "for col in categorical_variables:\n",
    "    ddf[col] = ddf[col].astype('category')\n",
    "ddf[numeric_variables] = ddf[numeric_variables].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN, STANDARD DEVIATION, MINIMUM, P25, P50, P75 AND MAXIMUM\n",
    "data_stats_post = pd.DataFrame.describe(ddf).transpose()\n",
    "data_stats_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN, STANDARD DEVIATION, MINIMUM, MAXIMUM AND COEFFICIENT OF VARIATION DISAGGREGATED BY PRIMARY KEY\n",
    "data_stats_by = ddf.groupby(primary_key).agg(['mean','std','min','max',lambda x: round(x.std()/abs(x.mean())*100,2) if abs(x.mean())!=0 else float('Inf')])\n",
    "data_stats_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE WITH PERCENTAGE OF MISSING VALUES, INVALID VALUES AND OUTLIERS\n",
    "# PERCENTAGE OF MISSING VALUES\n",
    "data_cleaning = pd.DataFrame(round(num_nan/len(ddf)*100,2))\n",
    "data_cleaning.columns =['%nan']\n",
    "\n",
    "# PERCENTAGE OF INVALID VALUES\n",
    "inv_values['invalid_values'] = inv_values['invalid_values'].astype('float')\n",
    "\n",
    "for i in numeric_variables:\n",
    "    j = i\n",
    "    j = inv_values['invalid_values'][inv_values['numeric_variable']==j]\n",
    "    j = j.values\n",
    "    data_cleaning.loc[i,'invalid_values'] = round(j[0]/len(ddf)*100,2)\n",
    "\n",
    "inv_perc = pd.DataFrame(data_cleaning['invalid_values'])\n",
    "\n",
    "# PERCENTAGE OF OUTLIERS\n",
    "for i in numeric_variables:\n",
    "    j = 'outliers_' + i[:3]\n",
    "    j = outlier_df['outlier_number'][outlier_df['outlier_name']==j]\n",
    "    j = j.values\n",
    "    data_cleaning.loc[i,'outliers'] = round(j[0]/len(ddf)*100,2)\n",
    "\n",
    "outlier_perc = pd.DataFrame(data_cleaning['outliers'])\n",
    "data_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk_value = ddf[primary_key].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME SERIES OF TARGET OF PRIMARY KEY VALUE\n",
    "target_p1 = []\n",
    "date_p1 = []\n",
    "\n",
    "# for pro in products:\n",
    "target_p1.append(ddf[target][ddf[primary_key]==pk_value])\n",
    "date_p1.append(ddf[time_variables][ddf[primary_key]==pk_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF TIME SERIES\n",
    "# for i in pk_list:    \n",
    "plt.plot(ddf[target][ddf[primary_key]==pk_value])\n",
    "plt.title('Serie de Tiempo de ' + target + ' de la Primary Key ' + primary_key + ': ' + str(pk_value))\n",
    "plt.ylabel(target)\n",
    "plt.xlabel('Time')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF AUTOCORRELATION FUNCTION\n",
    "plot_acf(ddf[target][ddf[primary_key]==pk_value], lags= 7, alpha=0.05)\n",
    "# print(acf(ddf[target][ddf[primary_key]==pk_value]))\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF PARTIAL AUTOCORRELATION FUNCTION\n",
    "# plot_pacf(ddf[target][ddf[primary_key]==pk_value],method='ywu')\n",
    "plot_pacf(ddf[target][ddf[primary_key]==pk_value],method='ols')\n",
    "# print(pacf(ddf[target][ddf[primary_key]==pk_value]))\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENTED DICKEY-FULLER TEST (STATIONARITY TEST: IF THE NULL HYPOTHESIS IS REJECTED, THEN THE SERIES IS STATIONARY)\n",
    "ADF = adfuller(ddf[target][ddf[primary_key]==pk_value].values)\n",
    "print('ADF Statistic: %f' % ADF[0])\n",
    "print('p-value: %f' % ADF[1])\n",
    "print('Critical Values:')\n",
    "for key, value in ADF[4].items(): \n",
    "    print('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREUSCH-PAGAN TEST (SEASONALITY TEST)\n",
    "seasonal_test = seasonal_decompose(tuple(ddf[ddf[primary_key]==pk_value][target]), model='Additive', freq=6)\n",
    "seasonal_test.seasonal\n",
    "seasonal_test.plot()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "02_descriptive_statistics",
  "notebookId": 813129968895745
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
