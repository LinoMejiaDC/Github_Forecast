{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xlrd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH WHERE THE FILES ARE SAVED\n",
    "databricks_path = './' #r'/dbfs/FileStore/tables/' # databricks file system\n",
    "azure_path = None #'/mnt/ddf/' # Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if azure_path is not None:\n",
    "    dbutils.fs.cp(azure_path + '/1_raw_data/framework_configuration.xlsx', databricks_path.replace('/dbfs/','dbfs:/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRAMEWORK CONFIGURATION\n",
    "wb = pd.ExcelFile(databricks_path+ r'/1_raw_data/framework_configuration.xlsx')\n",
    "ddf_config_var = wb.parse('Variables')\n",
    "ddf_config_kpi = wb.parse('KPI')\n",
    "ddf_config_par = wb.parse('Parameters')\n",
    "\n",
    "# ddf_config_var = pd.read_excel(path + r'framework_configuration_var.xlsx')\n",
    "# ddf_config_kpi = pd.read_excel(path + r'\\temp\\1_raw_data\\framework_configuration_kpi.xlsx')\n",
    "# ddf_config_par = pd.read_excel(path + r'framework_configuration_par.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION OF THE EXISTENCE OF THE FILES IN THE FOLDER\n",
    "data_source = ddf_config_var.loc[1,'DataSource']\n",
    "if azure_path is not None:\n",
    "    dbutils.fs.cp(azure_path + '/1_raw_data/' + data_source, databricks_path.replace('/dbfs/','dbfs:/'))\n",
    "\n",
    "file_exist = os.path.isfile(databricks_path + \"/1_raw_data/\" + data_source)\n",
    "if file_exist:\n",
    "    ddf = pd.read_excel(databricks_path + \"/1_raw_data/\" + data_source)\n",
    "else:\n",
    "    print('The file does not exist or does not have the established name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY KEY\n",
    "primary_key = ddf_config_var.loc[np.where(ddf_config_var[\"VariableUsage\"]=='PRIMARY')[0][0],'VariableName']\n",
    "\n",
    "# FILTER BY COLUMN\n",
    "filter_by = ddf_config_par.loc[0,'Value']\n",
    "\n",
    "# FILTER BY VALUE\n",
    "filter_value = ddf_config_par.loc[1,'Value']\n",
    "\n",
    "if str(filter_by)!='nan':\n",
    "    # PRIMARY KEY LIST WITH FILTER \n",
    "    pk_list = ddf[primary_key][ddf[filter_by]==filter_value].unique()\n",
    "else:\n",
    "    # PRIMARY KEY LIST \n",
    "    pk_list = ddf[primary_key].unique()\n",
    "\n",
    "column_name = ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='NUMERIC')[0],'VariableName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NW314MQ\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\NW314MQ\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\NW314MQ\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\NW314MQ\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_name</th>\n",
       "      <th>outlier_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outliers_Vol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outliers_Rev</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outliers_Pre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   outlier_name  outlier_number\n",
       "0  outliers_Vol               0\n",
       "1  outliers_Rev               0\n",
       "2  outliers_Pre               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='DATETIME')[0],'VariableName'])\n",
    "numeric_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='NUMERIC')[0],'VariableName'])\n",
    "categorical_variables = list(ddf_config_var.loc[np.where(ddf_config_var[\"VariableType\"]=='CATEGORICAL')[0],'VariableName'])\n",
    "\n",
    "# VARIABLES FORMAT\n",
    "ddf[time_variables] = ddf[time_variables].astype('object')\n",
    "for col in categorical_variables:\n",
    "    ddf[col] = ddf[col].astype('category')\n",
    "ddf[numeric_variables] = ddf[numeric_variables].astype('float')\n",
    "\n",
    "# NUMBER OF MISSING VALUES BY VARIABLE\n",
    "num_nan = ddf.isnull().sum()\n",
    "\n",
    "# NUMBER OF INVALID VALUES BY VARIABLE\n",
    "inv_values_aux = list()\n",
    "for i in numeric_variables:\n",
    "    inv_values_aux.append(ddf[i][np.logical_or(ddf[i]>float(ddf_config_var['UpperBound'][ddf_config_var['VariableName']==i]),ddf[i]<float(ddf_config_var['LowerBound'][ddf_config_var['VariableName']==i]))].count())\n",
    "inv_values = pd.DataFrame([numeric_variables, inv_values_aux]).transpose()\n",
    "inv_values.columns = ['numeric_variable','invalid_values']\n",
    "\n",
    "'''\n",
    "# REPLACEMENT OF INVALID VALUES BY THE CORRESPONDING LIMIT\n",
    "for cname in numeric_variables:\n",
    "    ddf[cname][ddf[cname]>float(ddf_config_var['UpperBound'][ddf_config_var['VariableName']==cname])] = float(ddf_config_var['UpperBound'][ddf_config_var['VariableName']==cname])\n",
    "    ddf[cname][ddf[cname]<float(ddf_config_var['LowerBound'][ddf_config_var['VariableName']==cname])] = float(ddf_config_var['LowerBound'][ddf_config_var['VariableName']==cname])\n",
    "'''\n",
    "\n",
    "# REPLACEMENT OF INVALID VALUES BY NAN\n",
    "for cname in numeric_variables:\n",
    "    ddf[cname][ddf[cname]>float(ddf_config_var['UpperBound'][ddf_config_var['VariableName']==cname])] = np.nan\n",
    "    ddf[cname][ddf[cname]<float(ddf_config_var['LowerBound'][ddf_config_var['VariableName']==cname])] = np.nan\n",
    "\n",
    "# OUTLIER FACTOR\n",
    "factor = 3\n",
    "\n",
    "outliers = []\n",
    "outliers_name = []\n",
    "\n",
    "for i in numeric_variables:\n",
    "    # DEFINITION OF LOWER AND UPPER LIMITS OF OUTLIERS CONSIDERING CRITERIA IQR BY PRIMARY KEY\n",
    "    locals()['iq_{0}'.format(i[:3])] = pd.DataFrame(ddf.groupby([primary_key])[i].quantile(.25))\n",
    "    locals()['iq_{0}'.format(i[:3])].columns = ['p25']\n",
    "    locals()['iq_{0}'.format(i[:3])]['p75'] = ddf.groupby([primary_key])[i].quantile(.75)\n",
    "    locals()['iq_{0}'.format(i[:3])]['iqr'] = locals()['iq_{0}'.format(i[:3])]['p75']-locals()['iq_{0}'.format(i[:3])]['p25']\n",
    "    locals()['iq_{0}'.format(i[:3])]['lo_lim'] = locals()['iq_{0}'.format(i[:3])]['p25']-factor*locals()['iq_{0}'.format(i[:3])]['iqr']\n",
    "    locals()['iq_{0}'.format(i[:3])]['up_lim'] = locals()['iq_{0}'.format(i[:3])]['p75']+factor*locals()['iq_{0}'.format(i[:3])]['iqr']\n",
    "    # NUMBER OF OUTLIERS\n",
    "    locals()['outliers_{0}'.format(i[:3])] = sum(ddf[i]<ddf.merge(locals()['iq_{0}'.format(i[:3])],left_on=primary_key,right_index=True)['lo_lim'].sort_index())+sum(ddf[i]>ddf.merge(locals()['iq_{0}'.format(i[:3])],left_on=primary_key,right_index=True)['up_lim'].sort_index())\n",
    "    outliers.append(locals()['outliers_{0}'.format(i[:3])])\n",
    "    outliers_name.append(\"outliers_\" + i[:3])\n",
    "    # REPLACEMENT OF OUTLIERS BY NAN\n",
    "    ddf[i][ddf[i]<ddf.merge(locals()['iq_{0}'.format(i[:3])],left_on=primary_key,right_index=True)['lo_lim'].sort_index()] = np.nan\n",
    "    ddf[i][ddf[i]>ddf.merge(locals()['iq_{0}'.format(i[:3])],left_on=primary_key,right_index=True)['up_lim'].sort_index()] = np.nan \n",
    "\n",
    "outlier_df = pd.DataFrame(outliers_name)\n",
    "outlier_df.columns = ['outlier_name']\n",
    "outlier_df['outlier_number'] = outliers\n",
    "\n",
    "# IMPUTATION OF DATA MISSING AND OUTLIERS BY MEAN BY PRIMARY KEY\n",
    "ddf[numeric_variables] = ddf.groupby(primary_key).transform(lambda x: x.fillna(x.mean()))\n",
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTATION OF CLEAN DATA\n",
    "writer = pd.ExcelWriter(databricks_path + r'/2_cleaned_data/clean_ddf.xlsx')\n",
    "ddf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# EXPORT OF VARIABLES\n",
    "preprocess1 = (databricks_path + r'/3_variables/var1_pre_processing.sav')\n",
    "pickle.dump((num_nan, inv_values), open(preprocess1, 'wb'))\n",
    "\n",
    "preprocess2 = (databricks_path + r'/3_variables/var2_pre_processing.sav')\n",
    "pickle.dump((outlier_df), open(preprocess2, 'wb'))\n",
    "\n",
    "frameworkconfig1 = (databricks_path + r'/3_variables/var1_framework_config.sav')\n",
    "pickle.dump(ddf_config_var, open(frameworkconfig1, 'wb'))\n",
    "\n",
    "frameworkconfig2 = (databricks_path + r'/3_variables/var2_framework_config.sav')\n",
    "pickle.dump(ddf_config_kpi, open(frameworkconfig2, 'wb'))\n",
    "\n",
    "frameworkconfig3 = (databricks_path + r'/3_variables/var3_framework_config.sav')\n",
    "pickle.dump(ddf_config_par, open(frameworkconfig3, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if azure_path is not None:\n",
    "    dbutils.fs.cp(databricks_path.replace('/dbfs/','dbfs:/') + \"/clean_ddf.xlsx\", azure_path + '/2_cleaned_data/clean_ddf.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "01_pre_processing",
  "notebookId": 684229195496892
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
