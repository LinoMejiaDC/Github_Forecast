{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "azure_path = None #'/mnt/ddf/' # Azure Blob Storage\n",
    "path = './' #r'/dbfs/FileStore/tables/' # databricks filesystem\n",
    "\n",
    "model_names = ['sarimax', 'ets']\n",
    "model_variables = ['forecast','mape','parameters']\n",
    "model_selection_metric = 'mape'\n",
    "\n",
    "##output_file = '/4_outputs/ddf_dashboard.csv'\n",
    "output_file = '/4_outputs/ddf_dashboard.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbutils.fs.cp(\"dbfs:/FileStore/tables/ddf_forecast.xlsx\", \"/mnt/ddf/\")\n",
    "\n",
    "# IMPORT OF FORECAST\n",
    "ddf = pd.read_excel(path + r'/4_outputs/ddf_predictions.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT OF VARIABLES FROM MODELING NOTEBOOK\n",
    "modeling = (path + r'/4_outputs/var_results_modeling.sav')\n",
    "results = pickle.load(open(modeling, 'rb'))\n",
    "\n",
    "# IMPORT OF DATA FROM FRAMEWORK CONFIGURATION\n",
    "frameworkconfig1 = (path + r'/3_variables/var1_framework_config.sav')\n",
    "ddf_config_var = pickle.load(open(frameworkconfig1, 'rb'))\n",
    "\n",
    "frameworkconfig2 = (path + r'/3_variables/var2_framework_config.sav')\n",
    "ddf_config_kpi = pickle.load(open(frameworkconfig2, 'rb'))\n",
    "\n",
    "frameworkconfig3 = (path + r'/3_variables/var3_framework_config.sav')\n",
    "ddf_config_par = pickle.load(open(frameworkconfig3, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Scructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: build a generic way of adding new models to the output, instead of changing this cell everytime a new model is implemented in the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured date column:  ['Date']\n",
      "Configured PK columns:  ['Unidade de Negocio', 'Product']\n",
      "Configured target column:  ['Volume (Un)']\n",
      "Could not find a reference column for the forecast. Adding a dummy one\n"
     ]
    }
   ],
   "source": [
    "n_levels = 5\n",
    "granularity_cols = ['Level_%i'%n for n in range(1, n_levels+1)]\n",
    "model_cols = [x+\"_\"+y for y in model_names for x in model_variables]\n",
    "model_selection_cols = ['BestModelName', 'Forecast','MAPE_Forecast', 'BestModelParameters', 'MAPE_Reference', 'Reference']\n",
    "mandatory_cols = ['DFU']\n",
    "\n",
    "output_cols = ['Date'] + mandatory_cols + granularity_cols + ['Target'] + model_cols + model_selection_cols\n",
    "\n",
    "# Get the Date columns from the configuration file\n",
    "date_column = ddf_config_var.VariableName[(ddf_config_var.VariableType.str.lower() == 'datetime') & \\\n",
    "                                          (ddf_config_var.VariableUsage.str.lower().isin(['analysis','time_series']))].values.tolist()\n",
    "if len(date_column) != 1:\n",
    "    raise Exception('Could not find the date column in the configuration file')\n",
    "print('Configured date column: ', date_column)\n",
    "\n",
    "# Get the primary key definition (granularity)\n",
    "pk_cols = ddf_config_var[ddf_config_var.PK > 0].sort_values('PK').VariableName.values.tolist()\n",
    "if len(pk_cols) == 0:\n",
    "    raise Exception('Could not find the PK columns in the configuration file')\n",
    "elif len(pk_cols) > n_levels:\n",
    "    raise Exception('Number of PK levels is greater than support by the tool (%i)'%n_levels)\n",
    "print('Configured PK columns: ', pk_cols)\n",
    "\n",
    "# Get the target definition\n",
    "target_column = ddf_config_var.VariableName[ddf_config_var.VariableUsage.str.lower() == 'target'].values.tolist()\n",
    "if len(target_column) != 1:\n",
    "    raise Exception('Could not find the PK columns in the configuration file')\n",
    "print('Configured target column: ', target_column)\n",
    "\n",
    "# Get reference definition\n",
    "ref_column = ddf_config_var.VariableName[(ddf_config_var.VariableType.str.lower() == 'numeric') & \\\n",
    "                                          (ddf_config_var.VariableUsage.str.lower() == 'reference')].values.tolist()\n",
    "if len(ref_column) != 1:\n",
    "    print('Could not find a reference column for the forecast. Adding a dummy one')\n",
    "    ref_column = ['DUMMY_REFERENCE']\n",
    "    ddf[ref_column[0]] = 0\n",
    "    ddf['MAPE_'+ref_column[0]] = np.nan\n",
    "else:\n",
    "    print('Configured forecast reference column: ', ref_column[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Output to the Expected Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming mapping\n",
    "renaming= {\n",
    "    date_column[0]: 'Date',\n",
    "    target_column[0] : 'Target',\n",
    "    ref_column[0]: 'Reference',\n",
    "    'MAPE_'+ref_column[0]: 'MAPE_Reference'\n",
    "}\n",
    "renaming.update(dict(zip(pk_cols, granularity_cols[:len(pk_cols)])))\n",
    "\n",
    "\n",
    "\n",
    "results = ddf.copy()\n",
    "results.rename(columns=renaming, inplace=True)\n",
    "results = results[np.intersect1d(output_cols, results.columns)]\n",
    "results[mandatory_cols] = ddf[mandatory_cols]\n",
    "\n",
    "# default levels\n",
    "for cname in granularity_cols[len(pk_cols):]:\n",
    "    results[cname] = 'N/A'\n",
    "\n",
    "# Best models\n",
    "scores = np.array([model_selection_metric + \"_\" + x for x in model_names])\n",
    "predictions = np.array([\"forecast_\" + x for x in model_names])\n",
    "\n",
    "results.loc[:,'BestModelName'] = np.array(model_names)[np.argmin(results[scores].values, axis=1)]\n",
    "results.loc[results[predictions[0]].isnull(), 'BestModelName'] = 'N/A'\n",
    "\n",
    "results['Forecast'] = [results['forecast_' + cname].values[i] if cname != 'N/A' else np.nan\n",
    "                       for i, cname in enumerate(results.BestModelName.values)]\n",
    "results['MAPE_Forecast'] = [results['mape_' + cname].values[i] if cname != 'N/A' else np.nan\n",
    "                            for i, cname in enumerate(results.BestModelName.values)]\n",
    "results['BestModelParameters'] = [results['parameters_' + cname].values[i] if cname != 'N/A' else np.nan\n",
    "                                  for i, cname in enumerate(results.BestModelName.values)]\n",
    "# Fix date format\n",
    "results['Date'] = pd.to_datetime(results.Date, format=ddf_config_var[ddf_config_var.VariableName == date_column[0]].Obs.values[0])\n",
    "results['Date'] = results.Date.dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_file)\n",
    "##results.to_csv(path + output_file, index=None, sep=';', encoding='latin1')\n",
    "results.to_excel(path + output_file, index=None, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if azure_path is not None:\n",
    "    dbutils.fs.cp(path.replace('/dbfs/','dbfs:/') + output_file, azure_path + '/4_outputs/' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "05_dashboard_prep",
  "notebookId": 2071923188220327
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
